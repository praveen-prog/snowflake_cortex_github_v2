{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with LLMOps using Snowflake Cortex and TruLens\n",
    "\n",
    "By completing this guide, you'll get started with LLMOps by building a RAG by combining [Cortex LLM Functions](https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions) and [Cortex Search](https://github.com/Snowflake-Labs/cortex-search?tab=readme-ov-file), and then using [TruLens](https://www.trulens.org/) to add observability and guardrails.\n",
    "\n",
    "Along the way, you will also learn how run TruLens feedback functions with Snowflake Cortex as the [feedback provider](https://www.trulens.org/trulens_eval/api/provider/), and how to [log TruLens traces and evaluation metrics to a Snowflake table](https://www.trulens.org/trulens_eval/tracking/logging/where_to_log/log_in_snowflake/#logging-in-snowflake). Last, we'll show how to use [TruLens guardrails](https://www.trulens.org/trulens_eval/guardrails/) for filtering retrieved context and reducing hallucination.\n",
    "\n",
    "Here is a summary of what you will be able to learn in each step by following this quickstart:\n",
    "\n",
    "- **Setup Environment**: Create a session to use Snowflake Cortex capabilities.\n",
    "- **Cortex Complete**: Use Cortex `Complete()` to call Mistral Large.\n",
    "- **Add Data**: Load and preprocess raw documentation from GitHub, and load to Cortex Search.\n",
    "- **Search**: Search over the data loaded to Cortex Search.\n",
    "- **Create a RAG**: Create a RAG with Cortex Search and Complete and add TruLens instrumentation.\n",
    "- **Feedback Functions**: Add context relevance, groundedness and answer relevance evaluations to the RAG.\n",
    "- **Application Testing**: Understand the performance of your RAG across a test set.\n",
    "- **Guardrails**: Add context filter guardrails to reduce hallucinations.\n",
    "- **Measure Improvement**: See the improved evaluation results after adding guardrails.\n",
    "\n",
    "### What are Cortex LLM Functions?\n",
    "\n",
    "Snowflake Cortex gives you instant access to industry-leading large language models (LLMs) trained by researchers at companies like Mistral, Reka, Meta, and Google, including Snowflake Arctic, an open enterprise-grade model developed by Snowflake.\n",
    "\n",
    "### What is Cortex Search?\n",
    "\n",
    "Cortex Search enables low-latency, high-quality search over your Snowflake data. Cortex Search powers a broad array of search experiences for Snowflake users including Retrieval Augmented Generation (RAG) applications leveraging Large Language Models (LLMs).\n",
    "\n",
    "### What is TruLens?\n",
    "\n",
    "[TruLens](https://www.trulens.org/) is a library for tracking and evaluating Generative AI applications. It provides an extensive set of feedback functions to systematically measure the quality of your LLM based applications. It also traces the internal steps of your application, and allows you to run feedback functions on any internal step. Feedback function results can be examined in a TruLens dashboard, or used at runtime as guardrails.\n",
    "\n",
    "### What You Will Learn\n",
    "- How to build a RAG with Cortex Search and Cortex LLM Functions.\n",
    "- How to use TruLens Feedback Functions and Tracing.\n",
    "- How to log TruLens Evaluation Results and Traces to Snowflake.\n",
    "- How to use TruLens Feedback Functions as Guardrails to reduce hallucination.\n",
    "\n",
    "### What You Will Build\n",
    "- A retrieval-augmented generation (RAG) app\n",
    "- An LLMOps pipeline\n",
    "- Context filter guardrails\n",
    "\n",
    "### Prerequisites\n",
    "- A Snowflake account with Cortex LLM Functions and Cortex Search enabled.  If you do not have a Snowflake account, you can register for a [free trial account](https://signup.snowflake.com/?utm_cta=quickstarts_&_fsi=yYZEVo4S&_fsi=yYZEVo4S).\n",
    "- A Snowflake account login with ACCOUNTADMIN role. If you have this role in your environment, you may choose to use it. If not, you will need to 1) Register for a free trial, 2) Use a different role that has the ability to create database, schema, tables, stages, tasks, user-defined functions, and stored procedures OR 3) Use an existing database and schema in which you are able to create the mentioned objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake-snowpark-python\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have an environment with the right packages installed, we can load our credentials and set our Snowflake connection in a jupyter notebook notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from snowflake.snowpark.session import Session\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "connection_params = {\n",
    "  \"account\":  os.environ.get(\"SNOWFLAKE_ACCOUNT\"),\n",
    "  \"user\": os.environ.get(\"SNOWFLAKE_USER\"),\n",
    "  \"password\": os.environ.get(\"SNOWFLAKE_USER_PASSWORD\"),\n",
    "  \"role\": os.environ.get(\"SNOWFLAKE_ROLE\"),\n",
    "  \"database\": os.environ.get(\"SNOWFLAKE_DATABASE\"),\n",
    "  \"schema\": os.environ.get(\"SNOWFLAKE_SCHEMA\"),\n",
    "  \"warehouse\": os.environ.get(\"SNOWFLAKE_WAREHOUSE\")\n",
    "}\n",
    "\n",
    "snowpark_session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/praveenhome/Desktop/PRAVEENBASE/SNOWFLAKE/cortex/snowflake_cortex_app/research/outputjson.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df =pd.read_csv(\"/Users/praveenhome/Desktop/PRAVEENBASE/SNOWFLAKE/cortex/snowflake_cortex_app/research/outputjson.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake.core\n",
    "!pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake\n",
    "!pip install snowflake-connector-python==2.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Snowflakes get their unique patterns through a complex process of crystallization that occurs as water vapor freezes in the atmosphere. Here's a simplified explanation:\n",
      "\n",
      "1. **Nucleation**: The process begins with a tiny particle in the atmosphere, such as a speck of dust or pollen, which acts as a nucleus. Water vapor condenses onto this nucleus and starts to freeze.\n",
      "\n",
      "2. **Crystal Growth**: As more water vapor freezes onto the initial ice crystal, it forms a hexagonal prism shape. This is because the water molecules arrange themselves in a hexagonal pattern due to their molecular structure.\n",
      "\n",
      "3. **Branching**: As the ice crystal grows, it can develop branches, or \"arms.\" The exact pattern of these branches is influenced by the temperature and humidity conditions in the atmosphere. For example, colder temperatures tend to produce simpler, more geometric shapes, while warmer temperatures (around -15°C or 5°F) can lead to more intricate, lacy patterns.\n",
      "\n",
      "4. **Individual Growth**: Each arm of a snowflake grows independently, influenced by slight differences in local conditions. This is why snowflakes are often asymmetrical.\n",
      "\n",
      "5. **Complex Patterns**: As the snowflake falls, it passes through different layers of the atmosphere with varying temperatures and humidity levels. These changes cause the crystal to grow in different ways, leading to the complex patterns we see in snowflakes.\n",
      "\n",
      "6. **Unique Shapes**: The nearly infinite combinations of temperature, humidity, and other atmospheric conditions mean that no two snowflakes form in exactly the same way, leading to their unique patterns.\n",
      "\n",
      "This process is incredibly sensitive to microscopic changes in conditions, which is why snowflakes are so diverse and beautiful.\n",
      "[\n",
      "  {\n",
      "    \"answer\": \"2012\",\n",
      "    \"score\": 0.9999238\n",
      "  }\n",
      "]\n",
      "0.8329001\n",
      "The Snowflake company was founded by Thierry Cruanes, Marcin Zukowski, and Benoit Dageville in 2012 and is based in Bozeman, Montana.\n",
      "La société Snowflake a été cofondée par Thierry Cruanes, Marcin Zukowski et Benoit Dageville en 2012 et est basée à Bozeman, Montana.\n",
      "{\n",
      "  \"label\": \"Europe\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from snowflake.cortex import Complete, ExtractAnswer, Sentiment, Summarize, Translate, ClassifyText\n",
    "\n",
    "text = \"\"\"\n",
    "    The Snowflake company was co-founded by Thierry Cruanes, Marcin Zukowski,\n",
    "    and Benoit Dageville in 2012 and is headquartered in Bozeman, Montana.\n",
    "\"\"\"\n",
    "\n",
    "print(Complete(\"mistral-large2\", \"how do snowflakes get their unique patterns?\"))\n",
    "print(ExtractAnswer(text, \"When was snowflake founded?\"))\n",
    "print(Sentiment(\"I really enjoyed this restaurant. Fantastic service!\"))\n",
    "print(Summarize(text))\n",
    "print(Translate(text, \"en\", \"fr\"))\n",
    "print(ClassifyText(\"France\", [\"Europe\", \"Asia\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cortex Complete\n",
    "\n",
    "With the session set, we have what need to call a Snowflake Cortex LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Streamlit is an open-source Python library that makes it easy to create and share custom web apps for machine learning and data science. It allows you to turn data scripts into shareable web apps in just a few lines of code. Here are some key features of Streamlit:\n",
      "\n",
      "1. **Easy to Use**: Streamlit is designed to be user-friendly, especially for those who are already familiar with Python. You can create interactive web apps using simple Python scripts.\n",
      "\n",
      "2. **Interactive Widgets**: Streamlit provides a variety of interactive widgets like sliders, text inputs, buttons, and more, which can be used to create dynamic and interactive applications.\n",
      "\n",
      "3. **Real-time Updates**: Any changes you make to your Python script are reflected in real-time in the web app, making it easy to iterate and develop quickly.\n",
      "\n",
      "4. **Deployment**: Streamlit apps can be easily deployed and shared with others. You can host your app on Streamlit's own cloud platform, Streamlit Cloud, or on other platforms like Heroku, AWS, and more.\n",
      "\n",
      "5. **Integration**: Streamlit integrates well with popular data science libraries like Pandas, NumPy, Matplotlib, and others, making it a powerful tool for data visualization and analysis.\n",
      "\n",
      "Here's a simple example of a Streamlit app:\n",
      "\n",
      "```python\n",
      "import streamlit as st\n",
      "\n",
      "st.title('My First Streamlit App')\n",
      "st.write('Hello, world!')\n",
      "\n",
      "name = st.text_input('Enter your name')\n",
      "if name:\n",
      "    st.write(f'Hello, {name}!')\n",
      "```\n",
      "\n",
      "To run this app, you would save the code in a Python file (e.g., `app.py`) and then run the following command in your terminal:\n",
      "\n",
      "```sh\n",
      "streamlit run app.py\n",
      "```\n",
      "\n",
      "This will start a local web server and open the app in your default web browser.\n"
     ]
    }
   ],
   "source": [
    "from snowflake.cortex import Complete\n",
    "\n",
    "try:\n",
    "    result = Complete(\"mistral-large2\", \"What is streamlit app?\")\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALTER ACCOUNT SET CORTEX_ENABLED_CROSS_REGION = 'AWS_US';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-openai in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-openai) (0.12.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-openai) (1.55.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2023.10.0)\n",
      "Requirement already satisfied: httpx in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.14.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.8.0)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (24.1)\n",
      "Requirement already satisfied: llama-index-embeddings-openai in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-embeddings-openai) (0.12.2)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-embeddings-openai) (1.55.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2023.10.0)\n",
      "Requirement already satisfied: httpx in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.14.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (0.8.0)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (24.1)\n",
      "Requirement already satisfied: llama-index-readers-github in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: httpx>=0.26.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-github) (0.27.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-github) (0.12.2)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-github) (0.4.0)\n",
      "Requirement already satisfied: anyio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx>=0.26.0->llama-index-readers-github) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx>=0.26.0->llama-index-readers-github) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx>=0.26.0->llama-index-readers-github) (1.0.2)\n",
      "Requirement already satisfied: idna in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx>=0.26.0->llama-index-readers-github) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx>=0.26.0->llama-index-readers-github) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.26.0->llama-index-readers-github) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2023.10.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.14.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (4.12.3)\n",
      "Requirement already satisfied: pandas in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (2.2.2)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (0.0.26)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.11.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (2.5)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (2.8.3+snowflake1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (1.16.0)\n",
      "Requirement already satisfied: llama-index in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: nest_asyncio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.12.2)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.6.3)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.3.2)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.4.0,>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.55.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (2023.10.0)\n",
      "Requirement already satisfied: httpx in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.27.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.14.1)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.5)\n",
      "Requirement already satisfied: pandas in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.15)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.11.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.5)\n",
      "Requirement already satisfied: anyio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.2)\n",
      "Requirement already satisfied: idna in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.3+snowflake1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.2->llama-index) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-openai\n",
    "!pip install llama-index-embeddings-openai\n",
    "!pip install llama-index-readers-github\n",
    "!pip install llama-index nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cortex Search\n",
    "\n",
    "Next, we'll turn to the retrieval component of our RAG and set up Cortex Search.\n",
    "\n",
    "This requires three steps:\n",
    "\n",
    "1. Read and preprocess unstructured documents.\n",
    "2. Embed the cleaned documents with Arctic Embed.\n",
    "3. Call the Cortex search service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess unstructured documents\n",
    "\n",
    "For this example, we want to load Cortex Search with documentation from Github about a popular open-source library, Streamlit. To do so, we'll use a GitHub data loader available from LlamaHub.\n",
    "\n",
    "Here we'll also expend some effort to clean up the text so we can get better search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch data: {'name': 'main', 'commit': {'sha': '28e75b319290ee52379b5181fc05f28f23042b9c', 'node_id': 'C_kwDOFkWFONoAKDI4ZTc1YjMxOTI5MGVlNTIzNzliNTE4MWZjMDVmMjhmMjMwNDJiOWM', 'commit': {'author': {'name': 'Debbie Matthews', 'email': 'debbie.matthews@snowflake.com', 'date': '2024-12-11T08:51:32Z'}, 'committer': {'name': 'GitHub', 'email': 'noreply@github.com', 'date': '2024-12-11T08:51:32Z'}, 'message': 'Fix text color in Flex container (#1200)', 'tree': {'sha': 'ad0c933ce6a0a5166c48f5fc827b25c5dc9b419c', 'url': 'https://api.github.com/repos/streamlit/docs/git/trees/ad0c933ce6a0a5166c48f5fc827b25c5dc9b419c'}, 'url': 'https://api.github.com/repos/streamlit/docs/git/commits/28e75b319290ee52379b5181fc05f28f23042b9c', 'comment_count': 0, 'verification': {'verified': True, 'reason': 'valid', 'signature': '-----BEGIN PGP SIGNATURE-----\\n\\nwsFcBAABCAAQBQJnWVKUCRC1aQ7uu5UhlAAAHVcQAFklhhcXqwJmFuY8VoKuwpS4\\nZTmeuAKBDEi+2bmYxsyLJAsD7Ltb+ujoiP/pDy2rjffJa33/igt8qFuOhBy103y0\\nWL6c5gD0gD7R3dN8OPr1RXRkpvC8yW2xpr0McrrE8utuUWwld9I45ODN1T0Qo6Sj\\nrmHgkqq24aoOZPwdO5Rl5XZsNssm32nJklPVNE4kmQpoFY/zZcUMaWITvRr5Q3dl\\njeywQ/H7O8Tqm2547rLu7YFQ9r7I6qr9hYqsR7h5hMysvhDiklDHDppNmkj12JZb\\nCYuLbP0Q+BS9tePLAcPOEEcuzEXLsgqQ+mPD6MSKoeCWCo19GlktKL9cGPxNC2pN\\n3MK3NJTqPVOOY7bLPYj2oDqK6DB7bFAefBIPwVlZJVrSrkSQIxpYRS9/9bp+oENf\\nNMgcCvtFpjKzsdUXw65anovcoZK1kcHMWwZL3kuScSZKsVTvqPPdawLFy3a8WtKt\\n+WlOMAxuSWe8MYgY2HFlt3Vyrp+Er2fanKApGAZJopLQ79fXpXVDsrD/HMQHhvQI\\nOGccPkqCGjPQFZnxGTgrAQ3MCqiZCIAjxvt0swWL1a92yhgr4yFJyfC+NWUZasOh\\nQXpqXxMLKSNkzYGZ5imjqz11HY3Z6whdcuhu9pEXx75O6Ht7U4sDwS38gxcMwgtU\\nTnJMFVDSAL8e25NXkBVb\\n=+coq\\n-----END PGP SIGNATURE-----\\n', 'payload': 'tree ad0c933ce6a0a5166c48f5fc827b25c5dc9b419c\\nparent 191d799be85120ba5103d7b06bea2ba63186cf32\\nauthor Debbie Matthews <debbie.matthews@snowflake.com> 1733907092 -0800\\ncommitter GitHub <noreply@github.com> 1733907092 -0800\\n\\nFix text color in Flex container (#1200)\\n\\n', 'verified_at': '2024-12-11T08:51:35Z'}}, 'url': 'https://api.github.com/repos/streamlit/docs/commits/28e75b319290ee52379b5181fc05f28f23042b9c', 'html_url': 'https://github.com/streamlit/docs/commit/28e75b319290ee52379b5181fc05f28f23042b9c', 'comments_url': 'https://api.github.com/repos/streamlit/docs/commits/28e75b319290ee52379b5181fc05f28f23042b9c/comments', 'author': {'login': 'sfc-gh-dmatthews', 'id': 135349133, 'node_id': 'U_kgDOCBFDjQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/135349133?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/sfc-gh-dmatthews', 'html_url': 'https://github.com/sfc-gh-dmatthews', 'followers_url': 'https://api.github.com/users/sfc-gh-dmatthews/followers', 'following_url': 'https://api.github.com/users/sfc-gh-dmatthews/following{/other_user}', 'gists_url': 'https://api.github.com/users/sfc-gh-dmatthews/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/sfc-gh-dmatthews/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/sfc-gh-dmatthews/subscriptions', 'organizations_url': 'https://api.github.com/users/sfc-gh-dmatthews/orgs', 'repos_url': 'https://api.github.com/users/sfc-gh-dmatthews/repos', 'events_url': 'https://api.github.com/users/sfc-gh-dmatthews/events{/privacy}', 'received_events_url': 'https://api.github.com/users/sfc-gh-dmatthews/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}, 'committer': {'login': 'web-flow', 'id': 19864447, 'node_id': 'MDQ6VXNlcjE5ODY0NDQ3', 'avatar_url': 'https://avatars.githubusercontent.com/u/19864447?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/web-flow', 'html_url': 'https://github.com/web-flow', 'followers_url': 'https://api.github.com/users/web-flow/followers', 'following_url': 'https://api.github.com/users/web-flow/following{/other_user}', 'gists_url': 'https://api.github.com/users/web-flow/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/web-flow/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/web-flow/subscriptions', 'organizations_url': 'https://api.github.com/users/web-flow/orgs', 'repos_url': 'https://api.github.com/users/web-flow/repos', 'events_url': 'https://api.github.com/users/web-flow/events{/privacy}', 'received_events_url': 'https://api.github.com/users/web-flow/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}, 'parents': [{'sha': '191d799be85120ba5103d7b06bea2ba63186cf32', 'url': 'https://api.github.com/repos/streamlit/docs/commits/191d799be85120ba5103d7b06bea2ba63186cf32', 'html_url': 'https://github.com/streamlit/docs/commit/191d799be85120ba5103d7b06bea2ba63186cf32'}]}, '_links': {'self': 'https://api.github.com/repos/streamlit/docs/branches/main', 'html': 'https://github.com/streamlit/docs/tree/main'}, 'protected': True, 'protection': {'enabled': True, 'required_status_checks': {'enforcement_level': 'off', 'contexts': [], 'checks': []}}, 'protection_url': 'https://api.github.com/repos/streamlit/docs/branches/main/protection'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Replace <your_github_token> with your token\n",
    "headers = {\"Authorization\": os.environ.get(\"GITHUB_TOKEN\")}\n",
    "response = requests.get(\n",
    "    \"https://api.github.com/repos/streamlit/docs/branches/main\", headers=headers\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Branch data: {response.json()}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.json()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "github_token = os.environ.get(\"GITHUB_TOKEN\")\n",
    "print(github_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader is <llama_index.readers.github.repository.base.GithubRepositoryReader object at 0x1375db3d0>\n",
      "current path: \n",
      "tree data: GitTreeResponseModel(sha='a0533c2d0222e13978295389e17f6fbd598acea6', url='https://api.github.com/repos/praveen-prog/docs/git/trees/a0533c2d0222e13978295389e17f6fbd598acea6', tree=[GitTreeResponseModel.GitTreeObject(path='README.md', mode='100644', type='blob', sha='1dc6372f7c1423fe04cc33381e8a5d51f11bbf55', url='https://api.github.com/repos/praveen-prog/docs/git/blobs/1dc6372f7c1423fe04cc33381e8a5d51f11bbf55', size=6), GitTreeResponseModel.GitTreeObject(path='content', mode='040000', type='tree', sha='90165d039994a29715754d9ec2b636dafb363579', url='https://api.github.com/repos/praveen-prog/docs/git/trees/90165d039994a29715754d9ec2b636dafb363579', size=None), GitTreeResponseModel.GitTreeObject(path='test.md', mode='100644', type='blob', sha='e69de29bb2d1d6434b8b29ae775ad8c2e48c5391', url='https://api.github.com/repos/praveen-prog/docs/git/blobs/e69de29bb2d1d6434b8b29ae775ad8c2e48c5391', size=0)], truncated=False)\n",
      "processing tree a0533c2d0222e13978295389e17f6fbd598acea6\n",
      "Checking README.md whether to FilterType.INCLUDE it based on the filter directories: ['content']\n",
      "Checking if README.md is a subdirectory of any of the filter directories\n",
      "ignoring README.md due to filter\n",
      "Checking content whether to FilterType.INCLUDE it based on the filter directories: ['content']\n",
      "Checking if content is a subdirectory of any of the filter directories\n",
      "tree object: GitTreeResponseModel.GitTreeObject(path='content', mode='040000', type='tree', sha='90165d039994a29715754d9ec2b636dafb363579', url='https://api.github.com/repos/praveen-prog/docs/git/trees/90165d039994a29715754d9ec2b636dafb363579', size=None)\n",
      "recursing into content\n",
      "\tcurrent path: content\n",
      "\ttree data: GitTreeResponseModel(sha='90165d039994a29715754d9ec2b636dafb363579', url='https://api.github.com/repos/praveen-prog/docs/git/trees/90165d039994a29715754d9ec2b636dafb363579', tree=[GitTreeResponseModel.GitTreeObject(path='test1.md', mode='100644', type='blob', sha='1b3799f664fc5811fbf27c08bbd72eb0682fc7c6', url='https://api.github.com/repos/praveen-prog/docs/git/blobs/1b3799f664fc5811fbf27c08bbd72eb0682fc7c6', size=279)], truncated=False)\n",
      "\tprocessing tree 90165d039994a29715754d9ec2b636dafb363579\n",
      "Checking content/test1.md whether to FilterType.INCLUDE it based on the filter directories: ['content']\n",
      "Checking if content/test1.md is a subdirectory of any of the filter directories\n",
      "Checking content/test1.md whether to FilterType.INCLUDE it based on the filter file extensions: ['.md']\n",
      "\ttree object: GitTreeResponseModel.GitTreeObject(path='test1.md', mode='100644', type='blob', sha='1b3799f664fc5811fbf27c08bbd72eb0682fc7c6', url='https://api.github.com/repos/praveen-prog/docs/git/blobs/1b3799f664fc5811fbf27c08bbd72eb0682fc7c6', size=279)\n",
      "\tfound blob test1.md\n",
      "\tblob and full paths: [(GitTreeResponseModel.GitTreeObject(path='test1.md', mode='100644', type='blob', sha='1b3799f664fc5811fbf27c08bbd72eb0682fc7c6', url='https://api.github.com/repos/praveen-prog/docs/git/blobs/1b3799f664fc5811fbf27c08bbd72eb0682fc7c6', size=279), 'content/test1.md')]\n",
      "blob and full paths: [(GitTreeResponseModel.GitTreeObject(path='test1.md', mode='100644', type='blob', sha='1b3799f664fc5811fbf27c08bbd72eb0682fc7c6', url='https://api.github.com/repos/praveen-prog/docs/git/blobs/1b3799f664fc5811fbf27c08bbd72eb0682fc7c6', size=279), 'content/test1.md')]\n",
      "Checking test.md whether to FilterType.INCLUDE it based on the filter directories: ['content']\n",
      "Checking if test.md is a subdirectory of any of the filter directories\n",
      "ignoring test.md due to filter\n",
      "got 1 blobs\n",
      "Time to get blobs ([('test1.md', 279)]): 0.21 seconds\n",
      "generating document for content/test1.md\n",
      "got 279 characters- adding to documents - content/test1.md\n",
      "Type is <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.readers.github import GithubRepositoryReader, GithubClient\n",
    "\n",
    "#github_token = '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'\n",
    "github_token = os.environ.get(\"GITHUB_TOKEN\")\n",
    "github_client = GithubClient(github_token=github_token, verbose=False)\n",
    "\n",
    "reader = GithubRepositoryReader(\n",
    "  github_client=github_client,\n",
    "  owner=\"praveen-prog\",\n",
    "  repo=\"docs\",\n",
    "  use_parser=False,\n",
    "  verbose=True,\n",
    "  filter_directories=(\n",
    "    [\"content\"],\n",
    "    GithubRepositoryReader.FilterType.INCLUDE,\n",
    "  ),\n",
    "  filter_file_extensions=(\n",
    "    [\".md\"],\n",
    "    GithubRepositoryReader.FilterType.INCLUDE,\n",
    "  )\n",
    ")\n",
    "\n",
    "print(f\"Reader is {reader}\")\n",
    "documents = reader.load_data(branch=\"main\")\n",
    "print(f\"Type is {type(documents)}\")\n",
    "\n",
    "\n",
    "def clean_up_text(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove unwanted characters and patterns in text input.\n",
    "\n",
    "    :param content: Text input.\n",
    "\n",
    "    :return: Cleaned version of original text input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fix hyphenated words broken by newline\n",
    "    content = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", content)\n",
    "\n",
    "    unwanted_patterns = [\"---\\nvisible: false\", \"---\", \"#\", \"slug:\"]\n",
    "    for pattern in unwanted_patterns:\n",
    "        content = re.sub(pattern, \"\", content)\n",
    "\n",
    "    # Remove all slugs starting with a \\ and stopping at the first space\n",
    "    content = re.sub(r\"\\\\slug: [^\\s]*\", \"\", content)\n",
    "\n",
    "    # normalize whitespace\n",
    "    content = re.sub(r\"\\s+\", \" \", content)\n",
    "    return content\n",
    "\n",
    "cleaned_documents = []\n",
    "\n",
    "for d in documents:\n",
    "    cleaned_text = clean_up_text(d.text)\n",
    "    d.text = cleaned_text\n",
    "    cleaned_documents.append(d)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='1b3799f664fc5811fbf27c08bbd72eb0682fc7c6', embedding=None, metadata={'file_path': 'content/test1.md', 'file_name': 'test1.md', 'url': 'https://api.github.com/praveen-prog/docs/blob/main/content/test1.md'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='This hackathon is an opportunity to riff with cutting-edge AI technology. Join us and get comfortable with a setlist for learning AI with Cortex Search for retrieval, Mistral LLM (mistral-large2) on Snowflake Cortex for generation, and Streamlit Community Cloud for the front end', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-huggingface in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-huggingface) (0.23.5)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-huggingface) (0.12.2)\n",
      "Requirement already satisfied: text-generation<0.8.0,>=0.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-huggingface) (0.7.0)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-huggingface) (2.5.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.46.3)\n",
      "Requirement already satisfied: filelock in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.11.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.14.1)\n",
      "Requirement already satisfied: jinja2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.5)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (1.1.1)\n",
      "Requirement already satisfied: psutil in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.11.0)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.23.1)\n",
      "Requirement already satisfied: anyio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.3)\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Using cached llama_index_embeddings_huggingface-0.4.0-py3-none-any.whl.metadata (767 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.23.5)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.12.2)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.11.0)\n",
      "Requirement already satisfied: aiohttp in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10.5)\n",
      "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Using cached minijinja-2.5.0-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.14.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.46.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.1)\n",
      "Requirement already satisfied: scipy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.11.0)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.23.1)\n",
      "Requirement already satisfied: anyio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.3)\n",
      "Using cached llama_index_embeddings_huggingface-0.4.0-py3-none-any.whl (8.6 kB)\n",
      "Using cached sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Using cached minijinja-2.5.0-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (1.7 MB)\n",
      "Installing collected packages: minijinja, sentence-transformers, llama-index-embeddings-huggingface\n",
      "Successfully installed llama-index-embeddings-huggingface-0.4.0 minijinja-2.5.0 sentence-transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-huggingface\n",
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the documents with Semantic Splitting\n",
    "\n",
    "We'll use Snowflake's Arctic Embed model available from HuggingFace to embed the documents. We'll also use Llama-Index's `SemanticSplitterNodeParser` for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\"Snowflake/snowflake-arctic-embed-m\")\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "  buffer_size=1, breakpoint_percentile_threshold=85, embed_model=embed_model\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the embed model and splitter, we can execute them in an ingestion pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "cortex_search_pipeline = IngestionPipeline(\n",
    "  transformations=[\n",
    "    splitter,\n",
    "  ],\n",
    ")\n",
    "\n",
    "results = cortex_search_pipeline.run(show_progress=False,documents=cleaned_documents)\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data to Cortex Search\n",
    "\n",
    "Now that we've embedded our documents, we're ready to load them to Cortex Search.\n",
    "\n",
    "Here we can use the same connection details as we set up for Cortex Complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f48fea8ec51434ba9db949071f68668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import snowflake.connector\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "snowflake_connector = snowflake.connector.connect(**connection_params)\n",
    "\n",
    "cursor = snowflake_connector.cursor()\n",
    "\n",
    "cursor.execute(\"CREATE OR REPLACE TABLE streamlit_docs(doc_text VARCHAR)\")\n",
    "for curr in tqdm(results):\n",
    "    cursor.execute(\"INSERT INTO streamlit_docs VALUES (%s)\", curr.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run in snowsql\n",
    "CREATE OR REPLACE CORTEX SEARCH SERVICE LLMOPS_DB.LLMOPS_SCHEMA.LLMOPS_CORTEX_SEARCH_SERVICE\n",
    "  ON doc_text\n",
    "  WAREHOUSE = LLMOPS_WH_M\n",
    "  TARGET_LAG = '1 hour'\n",
    "AS (\n",
    "  SELECT\n",
    "      doc_text\n",
    "  FROM LLMOPS_DB.LLMOPS_SCHEMA.streamlit_docs\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Cortex Search Service\n",
    "\n",
    "Next, we can go back to our python notebook and create a `CortexSearchRetreiver` class to connect to our cortex search service and add the `retrieve` method that we can leverage for calling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.core import Root\n",
    "from typing import List\n",
    "\n",
    "class CortexSearchRetriever:\n",
    "\n",
    "    def __init__(self, session: Session, limit_to_retrieve: int = 4):\n",
    "        self._session = session\n",
    "        self._limit_to_retrieve = limit_to_retrieve\n",
    "\n",
    "    def retrieve(self, query: str) -> List[str]:\n",
    "        root = Root(self._session)\n",
    "        cortex_search_service = (\n",
    "        root\n",
    "        .databases[os.environ.get(\"SNOWFLAKE_DATABASE\")]\n",
    "        .schemas[os.environ.get(\"SNOWFLAKE_SCHEMA\")]\n",
    "        .cortex_search_services[os.environ[\"SNOWFLAKE_CORTEX_SEARCH_SERVICE\"]]\n",
    "    )\n",
    "        resp = cortex_search_service.search(\n",
    "                query=query,\n",
    "                columns=[\"doc_text\"],\n",
    "                limit=self._limit_to_retrieve,\n",
    "            )\n",
    "\n",
    "        if resp.results:\n",
    "            return [curr[\"doc_text\"] for curr in resp.results]\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the retriever is created, we can test it out. Now that we have grounded access to the Streamlit docs, we can ask questions about using Streamlit, like \"How do I launch a streamlit app\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = CortexSearchRetriever(session=snowpark_session, limit_to_retrieve=4)\n",
    "\n",
    "retrieved_context = retriever.retrieve(query=\"How do I launch a streamlit app?\")\n",
    "\n",
    "len(retrieved_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This hackathon is an opportunity to riff with cutting-edge AI technology. Join us and get comfortable with a setlist for learning AI with Cortex Search for retrieval, Mistral LLM (mistral-large2) on Snowflake Cortex for generation, and Streamlit Community Cloud for the front end']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.retrieve(query=\"How do I launch a streamlit app?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a RAG with built-in observability\n",
    "\n",
    "Now that we've set up the components we need from Snowflake Cortex, we can build our RAG.\n",
    "\n",
    "We'll do this by creating a custom python class with each the methods we need. We'll also add TruLens instrumentation with the `@instrument` decorator to our app.\n",
    "\n",
    "The first thing we need to do however, is to set the database connection where we'll log the traces and evaluation results from our application. This way we have a stored record that we can use to understand the app's performance. This is done when initializing `Tru`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trulens\n",
    "!pip install trulens-connectors-snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running the TruLens dashboard requires providing a `password` to the `SnowflakeConnector`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Initialized with db url snowflake://%22praveensnowflake541%22:***@\"JCYRVUG-LR36187\"/%22LLMOPS_DB%22/%22LLMOPS_SCHEMA%22?role=%22ACCOUNTADMIN%22&warehouse=%22LLMOPS_WH_M%22 .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n",
      "Set TruLens workspace version tag: [('Statement executed successfully.',)]\n"
     ]
    }
   ],
   "source": [
    "from trulens.core import TruSession\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "\n",
    "tru_snowflake_connector = SnowflakeConnector(snowpark_session=snowpark_session)\n",
    "\n",
    "tru_session = TruSession(connector=tru_snowflake_connector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can construct the RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import instrument\n",
    "from snowflake.cortex import Complete\n",
    "\n",
    "\n",
    "class RAG_from_scratch:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.retriever = CortexSearchRetriever(session=snowpark_session, limit_to_retrieve=4)\n",
    "\n",
    "    @instrument\n",
    "    def retrieve_context(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        return self.retriever.retrieve(query)\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "          You are an expert assistant extracting information from context provided.\n",
    "          Answer the question based on the context. Be concise and do not hallucinate.\n",
    "          If you don't have the information just say so.\n",
    "          Context: {context_str}\n",
    "          Question:\n",
    "          {query}\n",
    "          Answer:\n",
    "        \"\"\"\n",
    "        return Complete(\"mistral-large2\", prompt)\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve_context(query)\n",
    "        return self.generate_completion(query, context_str)\n",
    "\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yes, the context mentions Streamlit Community Cloud for the front end.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.query(\" streamlit app?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trulens-providers-cortex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After constructing the RAG, we can set up the feedback functions we want to use to evaluate the RAG.\n",
    "\n",
    "Here, we'll use the [RAG Triad](https://www.trulens.org/trulens_eval/getting_started/core_concepts/rag_triad/). The RAG triad is made up of 3 evaluations along each edge of the RAG architecture: context relevance, groundedness and answer relevance.\n",
    "\n",
    "Satisfactory evaluations on each provides us confidence that our LLM app is free from hallucination.\n",
    "\n",
    "We will also use [LLM-as-a-Judge](https://arxiv.org/abs/2306.05685) evaluations, using Mistral Large on [Snowflake Cortex](https://www.trulens.org/trulens_eval/api/provider/cortex/) as the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input source will be set to __record__.app.retrieve_context.rets[:].collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.retrieve_context.rets[:] .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from trulens.providers.cortex.provider import Cortex\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "import numpy as np\n",
    "\n",
    "#provider = Cortex(snowpark_session.connection, \"llama3.1-8b\")\n",
    "provider = Cortex(snowpark_session, \"mistral-large2\")\n",
    "\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "    provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve_context.rets[:].collect())\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "    provider.context_relevance,\n",
    "    name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve_context.rets[:])\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "f_answer_relevance = (\n",
    "    Feedback(\n",
    "    provider.relevance,\n",
    "    name=\"Answer Relevance\")\n",
    "    .on_input()\n",
    "    .on_output()\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "feedbacks = [f_context_relevance,\n",
    "            f_answer_relevance,\n",
    "            f_groundedness,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the feedback functions to use, we can just add them to the application along with giving the application an ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "#from trulens.apps.custom import TruCustomApp\n",
    "tru_rag = TruCustomApp(rag,\n",
    "    app_id = 'RAG v1',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"What is streamlit?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "['112']\n"
     ]
    }
   ],
   "source": [
    "a='112'\n",
    "b=a.split()\n",
    "print(type(a))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the application is ready, we can run it on a test set of questions about streamlit to measure its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find an instance of DummyEndpoint. trulens will create an endpoint for cost tracking.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Streamlit is a tool for the front end.\n"
     ]
    }
   ],
   "source": [
    "with tru_rag as recording:\n",
    "    for prompt in prompts:\n",
    "        result = rag.query(prompt)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG with filters</th>\n",
       "      <th>base</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>10.122098</td>\n",
       "      <td>0.188017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG v1</th>\n",
       "      <th>base</th>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.124020</td>\n",
       "      <td>0.004255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Answer Relevance  Context Relevance  \\\n",
       "app_name         app_version                                        \n",
       "RAG with filters base                 1.000000                NaN   \n",
       "RAG v1           base                 0.395833           0.761905   \n",
       "\n",
       "                              Groundedness    latency  total_cost  \n",
       "app_name         app_version                                       \n",
       "RAG with filters base             0.117647  10.122098    0.188017  \n",
       "RAG v1           base             1.000000   1.124020    0.004255  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru_session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Guardrails\n",
    "\n",
    "In addition to making informed iteration, we can also directly use feedback results as guardrails at inference time. In particular, here we show how to use the context relevance score as a guardrail to filter out irrelevant context before it gets passed to the LLM. This both reduces hallucination and improves efficiency.\n",
    "\n",
    "To do so, we'll rebuild our RAG using the `@context-filter` decorator on the method we want to filter, and pass in the feedback function and threshold to use for guardrailing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.retrieve.rets .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w0/1sv3d34d1f99_k6nrjbyj6kc0000gn/T/ipykernel_92447/1532739201.py:6: DeprecationWarning: The `trulens_eval.guardrails` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
      "  from trulens_eval.guardrails.base import context_filter\n",
      "/var/folders/w0/1sv3d34d1f99_k6nrjbyj6kc0000gn/T/ipykernel_92447/1532739201.py:6: DeprecationWarning: The `trulens_eval.guardrails.base` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
      "  from trulens_eval.guardrails.base import context_filter\n"
     ]
    }
   ],
   "source": [
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = (\n",
    "    Feedback(provider.context_relevance, name = \"Context Relevance\")\n",
    ")\n",
    "\n",
    "from trulens_eval.guardrails.base import context_filter\n",
    "\n",
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = (\n",
    "    Feedback(provider.context_relevance, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve.rets)\n",
    ")\n",
    "\n",
    "class filtered_RAG_from_scratch:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.retriever = CortexSearchRetriever(session=snowpark_session, limit_to_retrieve=4)\n",
    "    @instrument\n",
    "    @context_filter(f_context_relevance_score, 0.75, keyword_for_prompt=\"query\")\n",
    "    def retrieve_context(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = self.retriever.retrieve(query)\n",
    "        return results\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        completion = Complete(\"mistral-large2\",query)\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve_context(query=query)\n",
    "        completion = self.generate_completion(query=query, context_str=context_str)\n",
    "        return completion\n",
    "\n",
    "filtered_rag = filtered_RAG_from_scratch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the new version of our app with the feedback functions we already defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function <function RAG_from_scratch.query at 0x32aed9080> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.filtered_RAG_from_scratch object at 0x32ae03c50> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
      "Function <function RAG_from_scratch.generate_completion at 0x32aed8fe0> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.filtered_RAG_from_scratch object at 0x32ae03c50> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
      "Function <function RAG_from_scratch.retrieve_context at 0x116f89940> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.filtered_RAG_from_scratch object at 0x32ae03c50> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n"
     ]
    }
   ],
   "source": [
    "from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "filtered_tru_rag = TruCustomApp(filtered_rag,\n",
    "    app_id = 'RAG with filters',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run it on a test set of questions about streamlit to measure its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages/trulens/core/feedback/feedback.py:974: UserWarning: Feedback function Context Relevance with aggregation <function mean at 0x116754d60> had no inputs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages/trulens/feedback/llm_provider.py:1521: UserWarning: Failed to process and remove trivial statements. Proceeding with all statements.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with filtered_tru_rag as recording:\n",
    "    for prompt in prompts:\n",
    "        filtered_rag.query(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG with filters</th>\n",
       "      <th>base</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>10.122098</td>\n",
       "      <td>0.188017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG v1</th>\n",
       "      <th>base</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.012737</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Answer Relevance  Context Relevance  \\\n",
       "app_name         app_version                                        \n",
       "RAG with filters base                 1.000000                NaN   \n",
       "RAG v1           base                 0.333333           0.333333   \n",
       "\n",
       "                              Groundedness    latency  total_cost  \n",
       "app_name         app_version                                       \n",
       "RAG with filters base             0.117647  10.122098    0.188017  \n",
       "RAG v1           base             1.000000   1.012737    0.003175  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru_session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion And Resources\n",
    "\n",
    "Congratulations! You've successfully built a RAG by combining Cortex Search and LLM Functions, adding in TruLens Feedback Functions as Observability. You also set up logging for TruLens to Snowflake, and added TruLens Guardrails to reduce hallucination.\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "- How to build a RAG with Cortex Search and Cortex LLM Functions.\n",
    "- How to use TruLens Feedback Functions and Tracing.\n",
    "- How to log TruLens Evaluation Results and Traces to Snowflake.\n",
    "- How to use TruLens Feedback Functions as Guardrails to reduce hallucination.\n",
    "\n",
    "### Related Resources\n",
    "\n",
    "- [Snowflake Cortex Documentation](https://docs.snowflake.com/en/guides-overview-ai-features)\n",
    "- [TruLens Documentation](https://trulens.org/)\n",
    "- [TruLens GitHub Repository](https://github.com/truera/trulens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "getting_started_llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
