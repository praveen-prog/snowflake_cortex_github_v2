{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with LLMOps using Snowflake Cortex and TruLens\n",
    "\n",
    "By completing this guide, you'll get started with LLMOps by building a RAG by combining [Cortex LLM Functions](https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions) and [Cortex Search](https://github.com/Snowflake-Labs/cortex-search?tab=readme-ov-file), and then using [TruLens](https://www.trulens.org/) to add observability and guardrails.\n",
    "\n",
    "Along the way, you will also learn how run TruLens feedback functions with Snowflake Cortex as the [feedback provider](https://www.trulens.org/trulens_eval/api/provider/), and how to [log TruLens traces and evaluation metrics to a Snowflake table](https://www.trulens.org/trulens_eval/tracking/logging/where_to_log/log_in_snowflake/#logging-in-snowflake). Last, we'll show how to use [TruLens guardrails](https://www.trulens.org/trulens_eval/guardrails/) for filtering retrieved context and reducing hallucination.\n",
    "\n",
    "Here is a summary of what you will be able to learn in each step by following this quickstart:\n",
    "\n",
    "- **Setup Environment**: Create a session to use Snowflake Cortex capabilities.\n",
    "- **Cortex Complete**: Use Cortex `Complete()` to call Mistral Large.\n",
    "- **Add Data**: Load and preprocess raw documentation from GitHub, and load to Cortex Search.\n",
    "- **Search**: Search over the data loaded to Cortex Search.\n",
    "- **Create a RAG**: Create a RAG with Cortex Search and Complete and add TruLens instrumentation.\n",
    "- **Feedback Functions**: Add context relevance, groundedness and answer relevance evaluations to the RAG.\n",
    "- **Application Testing**: Understand the performance of your RAG across a test set.\n",
    "- **Guardrails**: Add context filter guardrails to reduce hallucinations.\n",
    "- **Measure Improvement**: See the improved evaluation results after adding guardrails.\n",
    "\n",
    "### What are Cortex LLM Functions?\n",
    "\n",
    "Snowflake Cortex gives you instant access to industry-leading large language models (LLMs) trained by researchers at companies like Mistral, Reka, Meta, and Google, including Snowflake Arctic, an open enterprise-grade model developed by Snowflake.\n",
    "\n",
    "### What is Cortex Search?\n",
    "\n",
    "Cortex Search enables low-latency, high-quality search over your Snowflake data. Cortex Search powers a broad array of search experiences for Snowflake users including Retrieval Augmented Generation (RAG) applications leveraging Large Language Models (LLMs).\n",
    "\n",
    "### What is TruLens?\n",
    "\n",
    "[TruLens](https://www.trulens.org/) is a library for tracking and evaluating Generative AI applications. It provides an extensive set of feedback functions to systematically measure the quality of your LLM based applications. It also traces the internal steps of your application, and allows you to run feedback functions on any internal step. Feedback function results can be examined in a TruLens dashboard, or used at runtime as guardrails.\n",
    "\n",
    "### What You Will Learn\n",
    "- How to build a RAG with Cortex Search and Cortex LLM Functions.\n",
    "- How to use TruLens Feedback Functions and Tracing.\n",
    "- How to log TruLens Evaluation Results and Traces to Snowflake.\n",
    "- How to use TruLens Feedback Functions as Guardrails to reduce hallucination.\n",
    "\n",
    "### What You Will Build\n",
    "- A retrieval-augmented generation (RAG) app\n",
    "- An LLMOps pipeline\n",
    "- Context filter guardrails\n",
    "\n",
    "### Prerequisites\n",
    "- A Snowflake account with Cortex LLM Functions and Cortex Search enabled.  If you do not have a Snowflake account, you can register for a [free trial account](https://signup.snowflake.com/?utm_cta=quickstarts_&_fsi=yYZEVo4S&_fsi=yYZEVo4S).\n",
    "- A Snowflake account login with ACCOUNTADMIN role. If you have this role in your environment, you may choose to use it. If not, you will need to 1) Register for a free trial, 2) Use a different role that has the ability to create database, schema, tables, stages, tasks, user-defined functions, and stored procedures OR 3) Use an existing database and schema in which you are able to create the mentioned objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake-snowpark-python\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have an environment with the right packages installed, we can load our credentials and set our Snowflake connection in a jupyter notebook notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from snowflake.snowpark.session import Session\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "connection_params = {\n",
    "  \"account\":  os.environ.get(\"SNOWFLAKE_ACCOUNT\"),\n",
    "  \"user\": os.environ.get(\"SNOWFLAKE_USER\"),\n",
    "  \"password\": os.environ.get(\"SNOWFLAKE_USER_PASSWORD\"),\n",
    "  \"role\": os.environ.get(\"SNOWFLAKE_ROLE\"),\n",
    "  \"database\": os.environ.get(\"SNOWFLAKE_DATABASE\"),\n",
    "  \"schema\": os.environ.get(\"SNOWFLAKE_SCHEMA\"),\n",
    "  \"warehouse\": os.environ.get(\"SNOWFLAKE_WAREHOUSE\")\n",
    "}\n",
    "\n",
    "snowpark_session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/praveenhome/Desktop/PRAVEENBASE/SNOWFLAKE/cortex/snowflake_cortex_app/research/outputjson.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df =pd.read_csv(\"/Users/praveenhome/Desktop/PRAVEENBASE/SNOWFLAKE/cortex/snowflake_cortex_app/research/outputjson.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake.core\n",
    "!pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake\n",
    "!pip install snowflake-connector-python==2.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Snowflakes get their unique patterns through a complex process of crystallization that occurs as water vapor freezes in the atmosphere. Here's a simplified explanation:\n",
      "\n",
      "1. **Nucleation**: The process begins with a tiny particle in the atmosphere, such as a speck of dust or pollen, which acts as a nucleus. Water vapor condenses onto this nucleus and starts to freeze.\n",
      "\n",
      "2. **Crystal Growth**: As more water vapor freezes onto the initial ice crystal, it forms a hexagonal prism shape. This is because the water molecules arrange themselves in a hexagonal pattern due to their molecular structure.\n",
      "\n",
      "3. **Branching**: As the ice crystal grows, it can develop branches, or \"arms.\" The exact pattern of these branches is influenced by the temperature and humidity conditions in the atmosphere. For example, at around -15°C (5°F), the arms grow long and slender, while at around -5°C (23°F), the arms grow more complex, with side branches forming.\n",
      "\n",
      "4. **Individuality**: The unique pattern of each snowflake is due to the specific path it takes as it falls through the atmosphere. Each snowflake experiences slightly different temperatures and humidity levels, leading to its own unique pattern of branches.\n",
      "\n",
      "5. **Symmetry**: The six-sided symmetry of snowflakes is due to the hexagonal structure of the initial ice crystal. However, the complexity and exact shape of the branches can vary widely, leading to the vast array of beautiful patterns we see in snowflakes.\n",
      "\n",
      "It's important to note that while snowflakes are often unique, it's not entirely accurate to say that no two are alike. Simple snowflakes, especially at the beginning of their formation, can be quite similar. However, the vast majority of fully formed snowflakes are indeed unique due to the countless combinations of patterns that can form.\n",
      "\n",
      "This process is an active area of research in physics and atmospheric science, and there's still much to learn about the intricacies of snowflake formation.\n",
      "[\n",
      "  {\n",
      "    \"answer\": \"2012\",\n",
      "    \"score\": 0.9999238\n",
      "  }\n",
      "]\n",
      "0.8329001\n",
      "The Snowflake company was founded by Thierry Cruanes, Marcin Zukowski, and Benoit Dageville in 2012 and is based in Bozeman, Montana.\n",
      "La société Snowflake a été cofondée par Thierry Cruanes, Marcin Zukowski et Benoit Dageville en 2012 et est basée à Bozeman, Montana.\n",
      "{\n",
      "  \"label\": \"Europe\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from snowflake.cortex import Complete, ExtractAnswer, Sentiment, Summarize, Translate, ClassifyText\n",
    "\n",
    "text = \"\"\"\n",
    "    The Snowflake company was co-founded by Thierry Cruanes, Marcin Zukowski,\n",
    "    and Benoit Dageville in 2012 and is headquartered in Bozeman, Montana.\n",
    "\"\"\"\n",
    "\n",
    "print(Complete(\"mistral-large2\", \"how do snowflakes get their unique patterns?\"))\n",
    "print(ExtractAnswer(text, \"When was snowflake founded?\"))\n",
    "print(Sentiment(\"I really enjoyed this restaurant. Fantastic service!\"))\n",
    "print(Summarize(text))\n",
    "print(Translate(text, \"en\", \"fr\"))\n",
    "print(ClassifyText(\"France\", [\"Europe\", \"Asia\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cortex Complete\n",
    "\n",
    "With the session set, we have what need to call a Snowflake Cortex LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Streamlit is an open-source Python library that makes it easy to create and share custom web apps for machine learning and data science. It allows you to turn data scripts into shareable web apps in just a few lines of code. Here are some key features of Streamlit:\n",
      "\n",
      "1. **Easy to Use**: Streamlit is designed to be user-friendly, especially for those who are already familiar with Python. You can create interactive web apps using simple Python scripts.\n",
      "\n",
      "2. **Interactive Widgets**: Streamlit provides a variety of interactive widgets like sliders, text inputs, buttons, and more, which can be used to create dynamic and interactive applications.\n",
      "\n",
      "3. **Real-time Updates**: Any changes you make to your Python script are reflected in real-time in the web app, making it easy to iterate and develop quickly.\n",
      "\n",
      "4. **Deployment**: Streamlit apps can be easily deployed and shared with others. You can host your app on Streamlit's own cloud platform, Streamlit Cloud, or on other platforms like Heroku, AWS, and more.\n",
      "\n",
      "5. **Integration**: Streamlit integrates well with popular data science libraries like Pandas, NumPy, Matplotlib, and others, making it a powerful tool for data visualization and analysis.\n",
      "\n",
      "Here's a simple example of a Streamlit app:\n",
      "\n",
      "```python\n",
      "import streamlit as st\n",
      "\n",
      "st.title('My First Streamlit App')\n",
      "st.write('Hello, world!')\n",
      "\n",
      "name = st.text_input('Enter your name')\n",
      "if name:\n",
      "    st.write(f'Hello, {name}!')\n",
      "```\n",
      "\n",
      "To run this app, you would save the code in a Python file (e.g., `app.py`) and then run the following command in your terminal:\n",
      "\n",
      "```sh\n",
      "streamlit run app.py\n",
      "```\n",
      "\n",
      "This will start a local web server and open the app in your default web browser.\n"
     ]
    }
   ],
   "source": [
    "from snowflake.cortex import Complete\n",
    "\n",
    "try:\n",
    "    result = Complete(\"mistral-large2\", \"What is streamlit app?\")\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALTER ACCOUNT SET CORTEX_ENABLED_CROSS_REGION = 'AWS_US';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-openai in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-openai) (0.12.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-openai) (1.55.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2023.10.0)\n",
      "Requirement already satisfied: httpx in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.14.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.8.0)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-openai) (24.1)\n",
      "Requirement already satisfied: llama-index-embeddings-openai in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-embeddings-openai) (0.12.2)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-embeddings-openai) (1.55.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2023.10.0)\n",
      "Requirement already satisfied: httpx in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.14.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (0.8.0)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (24.1)\n",
      "Requirement already satisfied: llama-index-readers-github in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: httpx>=0.26.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-github) (0.27.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-github) (0.12.2)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-github) (0.4.0)\n",
      "Requirement already satisfied: anyio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx>=0.26.0->llama-index-readers-github) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx>=0.26.0->llama-index-readers-github) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx>=0.26.0->llama-index-readers-github) (1.0.2)\n",
      "Requirement already satisfied: idna in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx>=0.26.0->llama-index-readers-github) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx>=0.26.0->llama-index-readers-github) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.26.0->llama-index-readers-github) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2023.10.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.14.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (4.12.3)\n",
      "Requirement already satisfied: pandas in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (2.2.2)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (0.0.26)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.11.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (2.5)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (2.8.3+snowflake1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-github) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index-readers-github) (1.16.0)\n",
      "Requirement already satisfied: llama-index in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: nest_asyncio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.12.2)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.6.3)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.3.2)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.4.0,>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.55.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (2023.10.0)\n",
      "Requirement already satisfied: httpx in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.27.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.14.1)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.5)\n",
      "Requirement already satisfied: pandas in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.15)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.11.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.5)\n",
      "Requirement already satisfied: anyio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.2)\n",
      "Requirement already satisfied: idna in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.3+snowflake1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.2->llama-index) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-openai\n",
    "!pip install llama-index-embeddings-openai\n",
    "!pip install llama-index-readers-github\n",
    "!pip install llama-index nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cortex Search\n",
    "\n",
    "Next, we'll turn to the retrieval component of our RAG and set up Cortex Search.\n",
    "\n",
    "This requires three steps:\n",
    "\n",
    "1. Read and preprocess unstructured documents.\n",
    "2. Embed the cleaned documents with Arctic Embed.\n",
    "3. Call the Cortex search service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess unstructured documents\n",
    "\n",
    "For this example, we want to load Cortex Search with documentation from Github about a popular open-source library, Streamlit. To do so, we'll use a GitHub data loader available from LlamaHub.\n",
    "\n",
    "Here we'll also expend some effort to clean up the text so we can get better search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch data: {'name': 'main', 'commit': {'sha': 'd921ad84319e7f3ad5497094fa755e80ad4a8067', 'node_id': 'C_kwDONcSh7doAKGQ5MjFhZDg0MzE5ZTdmM2FkNTQ5NzA5NGZhNzU1ZTgwYWQ0YTgwNjc', 'commit': {'author': {'name': 'Praveen Kumar Chandran', 'email': 'praveenhome@Praveens-MacBook-Pro.local', 'date': '2024-12-11T22:19:29Z'}, 'committer': {'name': 'Praveen Kumar Chandran', 'email': 'praveenhome@Praveens-MacBook-Pro.local', 'date': '2024-12-11T22:19:29Z'}, 'message': 'test data addeed', 'tree': {'sha': 'a0533c2d0222e13978295389e17f6fbd598acea6', 'url': 'https://api.github.com/repos/praveen-prog/docs/git/trees/a0533c2d0222e13978295389e17f6fbd598acea6'}, 'url': 'https://api.github.com/repos/praveen-prog/docs/git/commits/d921ad84319e7f3ad5497094fa755e80ad4a8067', 'comment_count': 0, 'verification': {'verified': False, 'reason': 'unsigned', 'signature': None, 'payload': None, 'verified_at': None}}, 'url': 'https://api.github.com/repos/praveen-prog/docs/commits/d921ad84319e7f3ad5497094fa755e80ad4a8067', 'html_url': 'https://github.com/praveen-prog/docs/commit/d921ad84319e7f3ad5497094fa755e80ad4a8067', 'comments_url': 'https://api.github.com/repos/praveen-prog/docs/commits/d921ad84319e7f3ad5497094fa755e80ad4a8067/comments', 'author': None, 'committer': None, 'parents': [{'sha': 'f6e5f8b45b1c12fddff82a0827f67aac12437d14', 'url': 'https://api.github.com/repos/praveen-prog/docs/commits/f6e5f8b45b1c12fddff82a0827f67aac12437d14', 'html_url': 'https://github.com/praveen-prog/docs/commit/f6e5f8b45b1c12fddff82a0827f67aac12437d14'}]}, '_links': {'self': 'https://api.github.com/repos/praveen-prog/docs/branches/main', 'html': 'https://github.com/praveen-prog/docs/tree/main'}, 'protected': False, 'protection': {'enabled': False, 'required_status_checks': {'enforcement_level': 'off', 'contexts': [], 'checks': []}}, 'protection_url': 'https://api.github.com/repos/praveen-prog/docs/branches/main/protection'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Replace <your_github_token> with your token\n",
    "headers = {\"Authorization\": os.environ.get(\"GITHUB_TOKEN\")}\n",
    "response = requests.get(\n",
    "    \"https://api.github.com/repos/praveen-prog/docs/branches/main\", headers=headers\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Branch data: {response.json()}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.json()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "github_token = os.environ.get(\"GITHUB_TOKEN\")\n",
    "print(github_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader is <llama_index.readers.github.repository.base.GithubRepositoryReader object at 0x1694a2c50>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'commit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     13\u001b[0m reader \u001b[38;5;241m=\u001b[39m GithubRepositoryReader(\n\u001b[1;32m     14\u001b[0m   github_client\u001b[38;5;241m=\u001b[39mgithub_client,\n\u001b[1;32m     15\u001b[0m   owner\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpraveen-prog\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m   )\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReader is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreader\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m documents \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mload_data(branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_up_text\u001b[39m(content: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages/llama_index/readers/github/repository/base.py:308\u001b[0m, in \u001b[0;36mGithubRepositoryReader.load_data\u001b[0;34m(self, commit_sha, branch)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_data_from_commit(commit_sha)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m branch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_data_from_branch(branch)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must specify one of commit or branch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages/llama_index/readers/github/repository/base.py:268\u001b[0m, in \u001b[0;36mGithubRepositoryReader._load_data_from_branch\u001b[0;34m(self, branch)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_data_from_branch\u001b[39m(\u001b[38;5;28mself\u001b[39m, branch: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    Load data from a branch.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m    :return: list of documents\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     branch_data: GitBranchResponseModel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mrun_until_complete(\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_github_client\u001b[38;5;241m.\u001b[39mget_branch(\n\u001b[1;32m    270\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_owner, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_repo, branch, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    271\u001b[0m         )\n\u001b[1;32m    272\u001b[0m     )\n\u001b[1;32m    274\u001b[0m     tree_sha \u001b[38;5;241m=\u001b[39m branch_data\u001b[38;5;241m.\u001b[39mcommit\u001b[38;5;241m.\u001b[39mcommit\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39msha\n\u001b[1;32m    275\u001b[0m     blobs_and_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mrun_until_complete(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recurse_tree(tree_sha))\n",
      "File \u001b[0;32m~/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m~/miniconda3/envs/getting_started_llmops/lib/python3.11/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/miniconda3/envs/getting_started_llmops/lib/python3.11/asyncio/tasks.py:277\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages/llama_index/readers/github/repository/github_client.py:366\u001b[0m, in \u001b[0;36mGithubClient.get_branch\u001b[0;34m(self, owner, repo, branch, branch_name, timeout, retries)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither branch or branch_name must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    364\u001b[0m     branch \u001b[38;5;241m=\u001b[39m branch_name\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GitBranchResponseModel\u001b[38;5;241m.\u001b[39mfrom_json(\n\u001b[1;32m    367\u001b[0m     (\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetBranch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    370\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    371\u001b[0m             owner\u001b[38;5;241m=\u001b[39mowner,\n\u001b[1;32m    372\u001b[0m             repo\u001b[38;5;241m=\u001b[39mrepo,\n\u001b[1;32m    373\u001b[0m             branch\u001b[38;5;241m=\u001b[39mbranch,\n\u001b[1;32m    374\u001b[0m             timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    375\u001b[0m             retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    376\u001b[0m         )\n\u001b[1;32m    377\u001b[0m     )\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    378\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages/dataclasses_json/api.py:63\u001b[0m, in \u001b[0;36mDataClassJsonMixin.from_json\u001b[0;34m(cls, s, parse_float, parse_int, parse_constant, infer_missing, **kw)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_json\u001b[39m(\u001b[38;5;28mcls\u001b[39m: Type[A],\n\u001b[1;32m     51\u001b[0m               s: JsonData,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m               infer_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m A:\n\u001b[1;32m     58\u001b[0m     kvs \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(s,\n\u001b[1;32m     59\u001b[0m                      parse_float\u001b[38;5;241m=\u001b[39mparse_float,\n\u001b[1;32m     60\u001b[0m                      parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m     61\u001b[0m                      parse_constant\u001b[38;5;241m=\u001b[39mparse_constant,\n\u001b[1;32m     62\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dict(kvs, infer_missing\u001b[38;5;241m=\u001b[39minfer_missing)\n",
      "File \u001b[0;32m~/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages/dataclasses_json/api.py:70\u001b[0m, in \u001b[0;36mDataClassJsonMixin.from_dict\u001b[0;34m(cls, kvs, infer_missing)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_dict\u001b[39m(\u001b[38;5;28mcls\u001b[39m: Type[A],\n\u001b[1;32m     67\u001b[0m               kvs: Json,\n\u001b[1;32m     68\u001b[0m               \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m     69\u001b[0m               infer_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m A:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _decode_dataclass(\u001b[38;5;28mcls\u001b[39m, kvs, infer_missing)\n",
      "File \u001b[0;32m~/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages/dataclasses_json/core.py:185\u001b[0m, in \u001b[0;36m_decode_dataclass\u001b[0;34m(cls, kvs, infer_missing)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field\u001b[38;5;241m.\u001b[39minit:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m field_value \u001b[38;5;241m=\u001b[39m kvs[field\u001b[38;5;241m.\u001b[39mname]\n\u001b[1;32m    186\u001b[0m field_type \u001b[38;5;241m=\u001b[39m types[field\u001b[38;5;241m.\u001b[39mname]\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'commit'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.readers.github import GithubRepositoryReader, GithubClient\n",
    "\n",
    "#github_token = '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'\n",
    "github_token = os.environ.get(\"GITHUB_TOKEN\")\n",
    "github_client = GithubClient(github_token=github_token, verbose=False)\n",
    "\n",
    "reader = GithubRepositoryReader(\n",
    "  github_client=github_client,\n",
    "  owner=\"praveen-prog\",\n",
    "  repo=\"docs\",\n",
    "  use_parser=False,\n",
    "  verbose=True,\n",
    "  filter_directories=(\n",
    "    [\"content\"],\n",
    "    GithubRepositoryReader.FilterType.INCLUDE,\n",
    "  ),\n",
    "  filter_file_extensions=(\n",
    "    [\".md\"],\n",
    "    GithubRepositoryReader.FilterType.INCLUDE,\n",
    "  )\n",
    ")\n",
    "\n",
    "print(f\"Reader is {reader}\")\n",
    "documents = reader.load_data(branch=\"main\")\n",
    "print(f\"Type is {type(documents)}\")\n",
    "\n",
    "\n",
    "def clean_up_text(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove unwanted characters and patterns in text input.\n",
    "\n",
    "    :param content: Text input.\n",
    "\n",
    "    :return: Cleaned version of original text input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fix hyphenated words broken by newline\n",
    "    content = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", content)\n",
    "\n",
    "    unwanted_patterns = [\"---\\nvisible: false\", \"---\", \"#\", \"slug:\"]\n",
    "    for pattern in unwanted_patterns:\n",
    "        content = re.sub(pattern, \"\", content)\n",
    "\n",
    "    # Remove all slugs starting with a \\ and stopping at the first space\n",
    "    content = re.sub(r\"\\\\slug: [^\\s]*\", \"\", content)\n",
    "\n",
    "    # normalize whitespace\n",
    "    content = re.sub(r\"\\s+\", \" \", content)\n",
    "    return content\n",
    "\n",
    "cleaned_documents = []\n",
    "\n",
    "for d in documents:\n",
    "    cleaned_text = clean_up_text(d.text)\n",
    "    d.text = cleaned_text\n",
    "    cleaned_documents.append(d)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cleaned_documents[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_documents' is not defined"
     ]
    }
   ],
   "source": [
    "cleaned_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-huggingface in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-huggingface) (0.23.5)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-huggingface) (0.12.2)\n",
      "Requirement already satisfied: text-generation<0.8.0,>=0.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-huggingface) (0.7.0)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-llms-huggingface) (2.5.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.46.3)\n",
      "Requirement already satisfied: filelock in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.11.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.14.1)\n",
      "Requirement already satisfied: jinja2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.5)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (1.1.1)\n",
      "Requirement already satisfied: psutil in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.11.0)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.23.1)\n",
      "Requirement already satisfied: anyio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.3)\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Using cached llama_index_embeddings_huggingface-0.4.0-py3-none-any.whl.metadata (767 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.23.5)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.12.2)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.11.0)\n",
      "Requirement already satisfied: aiohttp in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10.5)\n",
      "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Using cached minijinja-2.5.0-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.14.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.46.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.1)\n",
      "Requirement already satisfied: scipy in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.11.0)\n",
      "Requirement already satisfied: click in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.23.1)\n",
      "Requirement already satisfied: anyio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.3)\n",
      "Using cached llama_index_embeddings_huggingface-0.4.0-py3-none-any.whl (8.6 kB)\n",
      "Using cached sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Using cached minijinja-2.5.0-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (1.7 MB)\n",
      "Installing collected packages: minijinja, sentence-transformers, llama-index-embeddings-huggingface\n",
      "Successfully installed llama-index-embeddings-huggingface-0.4.0 minijinja-2.5.0 sentence-transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-huggingface\n",
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the documents with Semantic Splitting\n",
    "\n",
    "We'll use Snowflake's Arctic Embed model available from HuggingFace to embed the documents. We'll also use Llama-Index's `SemanticSplitterNodeParser` for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\"Snowflake/snowflake-arctic-embed-m\")\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "  buffer_size=1, breakpoint_percentile_threshold=85, embed_model=embed_model\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the embed model and splitter, we can execute them in an ingestion pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mingestion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IngestionPipeline\n\u001b[1;32m      3\u001b[0m cortex_search_pipeline \u001b[38;5;241m=\u001b[39m IngestionPipeline(\n\u001b[1;32m      4\u001b[0m   transformations\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      5\u001b[0m     splitter,\n\u001b[1;32m      6\u001b[0m   ],\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m cortex_search_pipeline\u001b[38;5;241m.\u001b[39mrun(show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,documents\u001b[38;5;241m=\u001b[39mcleaned_documents)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(results))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_documents' is not defined"
     ]
    }
   ],
   "source": [
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "cortex_search_pipeline = IngestionPipeline(\n",
    "  transformations=[\n",
    "    splitter,\n",
    "  ],\n",
    ")\n",
    "\n",
    "results = cortex_search_pipeline.run(show_progress=False,documents=cleaned_documents)\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data to Cortex Search\n",
    "\n",
    "Now that we've embedded our documents, we're ready to load them to Cortex Search.\n",
    "\n",
    "Here we can use the same connection details as we set up for Cortex Complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f48fea8ec51434ba9db949071f68668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import snowflake.connector\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "snowflake_connector = snowflake.connector.connect(**connection_params)\n",
    "\n",
    "cursor = snowflake_connector.cursor()\n",
    "\n",
    "cursor.execute(\"CREATE OR REPLACE TABLE streamlit_docs(doc_text VARCHAR)\")\n",
    "for curr in tqdm(results):\n",
    "    cursor.execute(\"INSERT INTO streamlit_docs VALUES (%s)\", curr.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run in snowsql\n",
    "CREATE OR REPLACE CORTEX SEARCH SERVICE LLMOPS_DB.LLMOPS_SCHEMA.LLMOPS_CORTEX_SEARCH_SERVICE\n",
    "  ON doc_text\n",
    "  WAREHOUSE = LLMOPS_WH_M\n",
    "  TARGET_LAG = '1 hour'\n",
    "AS (\n",
    "  SELECT\n",
    "      doc_text\n",
    "  FROM LLMOPS_DB.LLMOPS_SCHEMA.streamlit_docs\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Cortex Search Service\n",
    "\n",
    "Next, we can go back to our python notebook and create a `CortexSearchRetreiver` class to connect to our cortex search service and add the `retrieve` method that we can leverage for calling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.core import Root\n",
    "from typing import List\n",
    "\n",
    "class CortexSearchRetriever:\n",
    "\n",
    "    def __init__(self, session: Session, limit_to_retrieve: int = 4):\n",
    "        self._session = session\n",
    "        self._limit_to_retrieve = limit_to_retrieve\n",
    "\n",
    "    def retrieve(self, query: str) -> List[str]:\n",
    "        root = Root(self._session)\n",
    "        cortex_search_service = (\n",
    "        root\n",
    "        .databases[os.environ.get(\"SNOWFLAKE_DATABASE\")]\n",
    "        .schemas[os.environ.get(\"SNOWFLAKE_SCHEMA\")]\n",
    "        .cortex_search_services[os.environ[\"SNOWFLAKE_CORTEX_SEARCH_SERVICE\"]]\n",
    "    )\n",
    "        resp = cortex_search_service.search(\n",
    "                query=query,\n",
    "                columns=[\"doc_text\"],\n",
    "                limit=self._limit_to_retrieve,\n",
    "            )\n",
    "\n",
    "        if resp.results:\n",
    "            return [curr[\"doc_text\"] for curr in resp.results]\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the retriever is created, we can test it out. Now that we have grounded access to the Streamlit docs, we can ask questions about using Streamlit, like \"How do I launch a streamlit app\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = CortexSearchRetriever(session=snowpark_session, limit_to_retrieve=4)\n",
    "\n",
    "retrieved_context = retriever.retrieve(query=\"How do I launch a streamlit app?\")\n",
    "\n",
    "len(retrieved_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This hackathon is an opportunity to riff with cutting-edge AI technology. Join us and get comfortable with a setlist for learning AI with Cortex Search for retrieval, Mistral LLM (mistral-large2) on Snowflake Cortex for generation, and Streamlit Community Cloud for the front end']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.retrieve(query=\"How do I launch a streamlit app?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a RAG with built-in observability\n",
    "\n",
    "Now that we've set up the components we need from Snowflake Cortex, we can build our RAG.\n",
    "\n",
    "We'll do this by creating a custom python class with each the methods we need. We'll also add TruLens instrumentation with the `@instrument` decorator to our app.\n",
    "\n",
    "The first thing we need to do however, is to set the database connection where we'll log the traces and evaluation results from our application. This way we have a stored record that we can use to understand the app's performance. This is done when initializing `Tru`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trulens\n",
    "!pip install trulens-connectors-snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running the TruLens dashboard requires providing a `password` to the `SnowflakeConnector`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Initialized with db url snowflake://%22praveensnowflake541%22:***@\"JCYRVUG-LR36187\"/%22LLMOPS_DB%22/%22LLMOPS_SCHEMA%22?role=%22ACCOUNTADMIN%22&warehouse=%22LLMOPS_WH_M%22 .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n",
      "Set TruLens workspace version tag: [('Statement executed successfully.',)]\n"
     ]
    }
   ],
   "source": [
    "from trulens.core import TruSession\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "\n",
    "tru_snowflake_connector = SnowflakeConnector(snowpark_session=snowpark_session)\n",
    "\n",
    "tru_session = TruSession(connector=tru_snowflake_connector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can construct the RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import instrument\n",
    "from snowflake.cortex import Complete\n",
    "\n",
    "\n",
    "class RAG_from_scratch:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.retriever = CortexSearchRetriever(session=snowpark_session, limit_to_retrieve=4)\n",
    "\n",
    "    @instrument\n",
    "    def retrieve_context(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        return self.retriever.retrieve(query)\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "          You are an expert assistant extracting information from context provided.\n",
    "          Answer the question based on the context. Be concise and do not hallucinate.\n",
    "          If you don't have the information just say so.\n",
    "          Context: {context_str}\n",
    "          Question:\n",
    "          {query}\n",
    "          Answer:\n",
    "        \"\"\"\n",
    "        return Complete(\"mistral-large2\", prompt)\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve_context(query)\n",
    "        return self.generate_completion(query, context_str)\n",
    "\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yes, the context mentions Streamlit Community Cloud for the front end.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.query(\" streamlit app?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trulens-providers-cortex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After constructing the RAG, we can set up the feedback functions we want to use to evaluate the RAG.\n",
    "\n",
    "Here, we'll use the [RAG Triad](https://www.trulens.org/trulens_eval/getting_started/core_concepts/rag_triad/). The RAG triad is made up of 3 evaluations along each edge of the RAG architecture: context relevance, groundedness and answer relevance.\n",
    "\n",
    "Satisfactory evaluations on each provides us confidence that our LLM app is free from hallucination.\n",
    "\n",
    "We will also use [LLM-as-a-Judge](https://arxiv.org/abs/2306.05685) evaluations, using Mistral Large on [Snowflake Cortex](https://www.trulens.org/trulens_eval/api/provider/cortex/) as the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input source will be set to __record__.app.retrieve_context.rets[:].collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.retrieve_context.rets[:] .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.retrieve.rets .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w0/1sv3d34d1f99_k6nrjbyj6kc0000gn/T/ipykernel_37853/3287386691.py:5: DeprecationWarning: The `trulens_eval.guardrails` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
      "  from trulens_eval.guardrails.base import context_filter\n",
      "/var/folders/w0/1sv3d34d1f99_k6nrjbyj6kc0000gn/T/ipykernel_37853/3287386691.py:5: DeprecationWarning: The `trulens_eval.guardrails.base` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
      "  from trulens_eval.guardrails.base import context_filter\n"
     ]
    }
   ],
   "source": [
    "from trulens.providers.cortex.provider import Cortex\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "\n",
    "from trulens_eval.guardrails.base import context_filter\n",
    "import numpy as np\n",
    "\n",
    "#provider = Cortex(snowpark_session.connection, \"llama3.1-8b\")\n",
    "provider = Cortex(snowpark_session, \"mistral-large2\")\n",
    "\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "    provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve_context.rets[:].collect())\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "    provider.context_relevance,\n",
    "    name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve_context.rets[:])\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "f_answer_relevance = (\n",
    "    Feedback(\n",
    "    provider.relevance,\n",
    "    name=\"Answer Relevance\")\n",
    "    .on_input()\n",
    "    .on_output()\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "feedbacks = [f_context_relevance,\n",
    "            f_answer_relevance,\n",
    "            f_groundedness,\n",
    "        ]\n",
    "\n",
    "f_context_relevance_score = (\n",
    "    Feedback(provider.context_relevance, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve.rets)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the feedback functions to use, we can just add them to the application along with giving the application an ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "#from trulens.apps.custom import TruCustomApp\n",
    "tru_rag = TruCustomApp(rag,\n",
    "    app_id = 'RAG v1',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"What is streamlit?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "['112']\n"
     ]
    }
   ],
   "source": [
    "a='112'\n",
    "b=a.split()\n",
    "print(type(a))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the application is ready, we can run it on a test set of questions about streamlit to measure its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find an instance of DummyEndpoint. trulens will create an endpoint for cost tracking.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Streamlit is a tool for the front end.\n"
     ]
    }
   ],
   "source": [
    "with tru_rag as recording:\n",
    "    for prompt in prompts:\n",
    "        result = rag.query(prompt)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG with filters</th>\n",
       "      <th>base</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>10.122098</td>\n",
       "      <td>0.188017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG v1</th>\n",
       "      <th>base</th>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.124020</td>\n",
       "      <td>0.004255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Answer Relevance  Context Relevance  \\\n",
       "app_name         app_version                                        \n",
       "RAG with filters base                 1.000000                NaN   \n",
       "RAG v1           base                 0.395833           0.761905   \n",
       "\n",
       "                              Groundedness    latency  total_cost  \n",
       "app_name         app_version                                       \n",
       "RAG with filters base             0.117647  10.122098    0.188017  \n",
       "RAG v1           base             1.000000   1.124020    0.004255  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru_session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import instrument\n",
    "from snowflake.cortex import Complete\n",
    "\n",
    "\n",
    "class RAG_from_scratch:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.retriever = CortexSearchRetriever(session=snowpark_session, limit_to_retrieve=4)\n",
    "\n",
    "    @instrument\n",
    "    @context_filter(f_context_relevance_score, 0.20, keyword_for_prompt=\"query\")\n",
    "    def retrieve_context(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        return self.retriever.retrieve(query)\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "          You are an expert assistant extracting information from context provided.\n",
    "          Answer the question based on the context. Be concise and do not hallucinate.\n",
    "          If you don't have the information just say so.\n",
    "          Context: {context_str}\n",
    "          Question:\n",
    "          {query}\n",
    "          Answer:\n",
    "        \"\"\"\n",
    "        return Complete(\"mistral-large2\", prompt)\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve_context(query)\n",
    "        return self.generate_completion(query, context_str)\n",
    "\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Streamlit is a tool for the front end.\n"
     ]
    }
   ],
   "source": [
    "with tru_rag as recording:\n",
    "    for prompt in prompts:\n",
    "        result = rag.query(prompt)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Guardrails\n",
    "\n",
    "In addition to making informed iteration, we can also directly use feedback results as guardrails at inference time. In particular, here we show how to use the context relevance score as a guardrail to filter out irrelevant context before it gets passed to the LLM. This both reduces hallucination and improves efficiency.\n",
    "\n",
    "To do so, we'll rebuild our RAG using the `@context-filter` decorator on the method we want to filter, and pass in the feedback function and threshold to use for guardrailing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.retrieve.rets .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w0/1sv3d34d1f99_k6nrjbyj6kc0000gn/T/ipykernel_92447/1532739201.py:6: DeprecationWarning: The `trulens_eval.guardrails` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
      "  from trulens_eval.guardrails.base import context_filter\n",
      "/var/folders/w0/1sv3d34d1f99_k6nrjbyj6kc0000gn/T/ipykernel_92447/1532739201.py:6: DeprecationWarning: The `trulens_eval.guardrails.base` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
      "  from trulens_eval.guardrails.base import context_filter\n"
     ]
    }
   ],
   "source": [
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = (\n",
    "    Feedback(provider.context_relevance, name = \"Context Relevance\")\n",
    ")\n",
    "\n",
    "from trulens_eval.guardrails.base import context_filter\n",
    "\n",
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = (\n",
    "    Feedback(provider.context_relevance, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve.rets)\n",
    ")\n",
    "\n",
    "class filtered_RAG_from_scratch:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.retriever = CortexSearchRetriever(session=snowpark_session, limit_to_retrieve=4)\n",
    "    @instrument\n",
    "    @context_filter(f_context_relevance_score, 0.75, keyword_for_prompt=\"query\")\n",
    "    def retrieve_context(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = self.retriever.retrieve(query)\n",
    "        return results\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        completion = Complete(\"mistral-large2\",query)\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve_context(query=query)\n",
    "        completion = self.generate_completion(query=query, context_str=context_str)\n",
    "        return completion\n",
    "\n",
    "filtered_rag = filtered_RAG_from_scratch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the new version of our app with the feedback functions we already defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function <function RAG_from_scratch.query at 0x32aed9080> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.filtered_RAG_from_scratch object at 0x32ae03c50> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
      "Function <function RAG_from_scratch.generate_completion at 0x32aed8fe0> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.filtered_RAG_from_scratch object at 0x32ae03c50> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
      "Function <function RAG_from_scratch.retrieve_context at 0x116f89940> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.filtered_RAG_from_scratch object at 0x32ae03c50> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n"
     ]
    }
   ],
   "source": [
    "from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "filtered_tru_rag = TruCustomApp(filtered_rag,\n",
    "    app_id = 'RAG with filters',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run it on a test set of questions about streamlit to measure its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages/trulens/core/feedback/feedback.py:974: UserWarning: Feedback function Context Relevance with aggregation <function mean at 0x116754d60> had no inputs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praveenhome/miniconda3/envs/getting_started_llmops/lib/python3.11/site-packages/trulens/feedback/llm_provider.py:1521: UserWarning: Failed to process and remove trivial statements. Proceeding with all statements.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with filtered_tru_rag as recording:\n",
    "    for prompt in prompts:\n",
    "        filtered_rag.query(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG with filters</th>\n",
       "      <th>base</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>10.122098</td>\n",
       "      <td>0.188017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG v1</th>\n",
       "      <th>base</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.012737</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Answer Relevance  Context Relevance  \\\n",
       "app_name         app_version                                        \n",
       "RAG with filters base                 1.000000                NaN   \n",
       "RAG v1           base                 0.333333           0.333333   \n",
       "\n",
       "                              Groundedness    latency  total_cost  \n",
       "app_name         app_version                                       \n",
       "RAG with filters base             0.117647  10.122098    0.188017  \n",
       "RAG v1           base             1.000000   1.012737    0.003175  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru_session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion And Resources\n",
    "\n",
    "Congratulations! You've successfully built a RAG by combining Cortex Search and LLM Functions, adding in TruLens Feedback Functions as Observability. You also set up logging for TruLens to Snowflake, and added TruLens Guardrails to reduce hallucination.\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "- How to build a RAG with Cortex Search and Cortex LLM Functions.\n",
    "- How to use TruLens Feedback Functions and Tracing.\n",
    "- How to log TruLens Evaluation Results and Traces to Snowflake.\n",
    "- How to use TruLens Feedback Functions as Guardrails to reduce hallucination.\n",
    "\n",
    "### Related Resources\n",
    "\n",
    "- [Snowflake Cortex Documentation](https://docs.snowflake.com/en/guides-overview-ai-features)\n",
    "- [TruLens Documentation](https://trulens.org/)\n",
    "- [TruLens GitHub Repository](https://github.com/truera/trulens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "getting_started_llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
